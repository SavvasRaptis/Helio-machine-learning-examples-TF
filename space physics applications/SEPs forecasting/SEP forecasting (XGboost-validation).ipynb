{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf30b9ed-d763-4f9b-9a11-d067d34ebbec",
   "metadata": {},
   "source": [
    "## Original Publication\n",
    "\n",
    "See the original publication of this work in the following link: https://www.swsc-journal.org/articles/swsc/abs/2021/01/swsc210024/swsc210024.html\n",
    "\n",
    "Aminalragia-Giamini, Sigiava, et al. \"Solar Energetic Particle Event occurrence prediction using Solar Flare Soft X-ray measurements and Machine Learning.\" Journal of Space Weather and Space Climate 11 (2021): 59.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a378b43",
   "metadata": {},
   "source": [
    "# Loading Data \n",
    "\n",
    "## Importing libraries and data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20016c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import sys\n",
    "from os import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras \n",
    "import xgboost as xgb\n",
    "\n",
    "x_train = pd.read_pickle(\"x_train.pkl\")  \n",
    "x_test = pd.read_pickle(\"x_test.pkl\")  \n",
    "y_train = pd.read_pickle(\"y_train.pkl\")  \n",
    "y_test = pd.read_pickle(\"y_test.pkl\")  \n",
    "\n",
    "# number of different classes\n",
    "n_SEPS =  226\n",
    "n_flares = 17875\n",
    "n_sample = n_SEPS +n_flares\n",
    "columns_to_use = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','17','20','21','22','28','39','40',\n",
    "                       '41','42','43','44','45','46','47','48']\n",
    "number_of_classes = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae342553-12a1-45ca-b0a0-36e920a330e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Savva\\AppData\\Local\\Temp\\ipykernel_18824\\4287163944.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  x_total = x_train.append(x_test)\n",
      "C:\\Users\\Savva\\AppData\\Local\\Temp\\ipykernel_18824\\4287163944.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_total = y_train.append(y_test)\n"
     ]
    }
   ],
   "source": [
    "x_total = x_train.append(x_test)\n",
    "y_total = y_train.append(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e4783",
   "metadata": {},
   "source": [
    "## Prepare validation\n",
    "\n",
    "Establish validation method below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b48ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from xgboost import cv\n",
    "\n",
    "sample_weight = compute_sample_weight(class_weight='balanced',y=y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10706183-fa4d-46f1-8a6a-33bc4f67865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(x_total, label=y_total)\n",
    "\n",
    "params={\"objective\" : \"binary:logistic\", 'learning_rate' :0.01, 'max_depth':20}\n",
    "\n",
    "xgb_cv = cv(dtrain=d_train, params =params, nfold=50, metrics =\"auc\", num_boost_round=50,as_pandas =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ad755c-6d22-48e0-8483-b518395f4294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.893975</td>\n",
       "      <td>0.008823</td>\n",
       "      <td>0.865043</td>\n",
       "      <td>0.108240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.895883</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.870884</td>\n",
       "      <td>0.110656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.897707</td>\n",
       "      <td>0.008441</td>\n",
       "      <td>0.870993</td>\n",
       "      <td>0.110608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.899231</td>\n",
       "      <td>0.008645</td>\n",
       "      <td>0.870957</td>\n",
       "      <td>0.110688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.900011</td>\n",
       "      <td>0.010210</td>\n",
       "      <td>0.870782</td>\n",
       "      <td>0.110735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.901944</td>\n",
       "      <td>0.010644</td>\n",
       "      <td>0.874984</td>\n",
       "      <td>0.105207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.903640</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>0.877366</td>\n",
       "      <td>0.103711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.905018</td>\n",
       "      <td>0.011112</td>\n",
       "      <td>0.878862</td>\n",
       "      <td>0.104663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.908456</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.884619</td>\n",
       "      <td>0.105666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.911940</td>\n",
       "      <td>0.015478</td>\n",
       "      <td>0.884255</td>\n",
       "      <td>0.106524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.917048</td>\n",
       "      <td>0.016401</td>\n",
       "      <td>0.883928</td>\n",
       "      <td>0.106890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.921526</td>\n",
       "      <td>0.015827</td>\n",
       "      <td>0.883953</td>\n",
       "      <td>0.107177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.923403</td>\n",
       "      <td>0.015486</td>\n",
       "      <td>0.884099</td>\n",
       "      <td>0.107226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.926320</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.885470</td>\n",
       "      <td>0.106431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.927658</td>\n",
       "      <td>0.013864</td>\n",
       "      <td>0.888541</td>\n",
       "      <td>0.101951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.928602</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>0.890818</td>\n",
       "      <td>0.102645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.930901</td>\n",
       "      <td>0.012465</td>\n",
       "      <td>0.894751</td>\n",
       "      <td>0.100418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.932019</td>\n",
       "      <td>0.011421</td>\n",
       "      <td>0.894647</td>\n",
       "      <td>0.100435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.932679</td>\n",
       "      <td>0.010957</td>\n",
       "      <td>0.896842</td>\n",
       "      <td>0.100975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.933862</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.902965</td>\n",
       "      <td>0.095437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.934024</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.905206</td>\n",
       "      <td>0.095486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.934727</td>\n",
       "      <td>0.010160</td>\n",
       "      <td>0.905133</td>\n",
       "      <td>0.095690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.935721</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.906155</td>\n",
       "      <td>0.095622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.936179</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.907237</td>\n",
       "      <td>0.096224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.937854</td>\n",
       "      <td>0.008887</td>\n",
       "      <td>0.911485</td>\n",
       "      <td>0.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.937937</td>\n",
       "      <td>0.008909</td>\n",
       "      <td>0.911583</td>\n",
       "      <td>0.090592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.938273</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>0.913578</td>\n",
       "      <td>0.088687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.938308</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>0.913598</td>\n",
       "      <td>0.088667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.938364</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>0.913605</td>\n",
       "      <td>0.088819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.938397</td>\n",
       "      <td>0.009046</td>\n",
       "      <td>0.913667</td>\n",
       "      <td>0.088876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.938445</td>\n",
       "      <td>0.009051</td>\n",
       "      <td>0.913856</td>\n",
       "      <td>0.089084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.938610</td>\n",
       "      <td>0.009089</td>\n",
       "      <td>0.913868</td>\n",
       "      <td>0.089064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.938730</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>0.913821</td>\n",
       "      <td>0.089084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.938850</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.913875</td>\n",
       "      <td>0.088996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.938945</td>\n",
       "      <td>0.008936</td>\n",
       "      <td>0.914201</td>\n",
       "      <td>0.089142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.939119</td>\n",
       "      <td>0.008783</td>\n",
       "      <td>0.914233</td>\n",
       "      <td>0.089012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.939233</td>\n",
       "      <td>0.008827</td>\n",
       "      <td>0.914381</td>\n",
       "      <td>0.088984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.939582</td>\n",
       "      <td>0.008942</td>\n",
       "      <td>0.914257</td>\n",
       "      <td>0.089050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.939693</td>\n",
       "      <td>0.008852</td>\n",
       "      <td>0.914335</td>\n",
       "      <td>0.089067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.939717</td>\n",
       "      <td>0.008860</td>\n",
       "      <td>0.914361</td>\n",
       "      <td>0.089032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.939920</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>0.914369</td>\n",
       "      <td>0.089031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.940195</td>\n",
       "      <td>0.008699</td>\n",
       "      <td>0.916003</td>\n",
       "      <td>0.089530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.940306</td>\n",
       "      <td>0.008703</td>\n",
       "      <td>0.915981</td>\n",
       "      <td>0.089515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.940479</td>\n",
       "      <td>0.008730</td>\n",
       "      <td>0.915893</td>\n",
       "      <td>0.089429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.940492</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>0.917242</td>\n",
       "      <td>0.088562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.940510</td>\n",
       "      <td>0.008738</td>\n",
       "      <td>0.917192</td>\n",
       "      <td>0.088515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.940525</td>\n",
       "      <td>0.008740</td>\n",
       "      <td>0.917245</td>\n",
       "      <td>0.088578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.940539</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.917122</td>\n",
       "      <td>0.088480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.940551</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>0.917238</td>\n",
       "      <td>0.088546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.941024</td>\n",
       "      <td>0.008394</td>\n",
       "      <td>0.917266</td>\n",
       "      <td>0.088635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
       "0         0.893975       0.008823       0.865043      0.108240\n",
       "1         0.895883       0.008165       0.870884      0.110656\n",
       "2         0.897707       0.008441       0.870993      0.110608\n",
       "3         0.899231       0.008645       0.870957      0.110688\n",
       "4         0.900011       0.010210       0.870782      0.110735\n",
       "5         0.901944       0.010644       0.874984      0.105207\n",
       "6         0.903640       0.010396       0.877366      0.103711\n",
       "7         0.905018       0.011112       0.878862      0.104663\n",
       "8         0.908456       0.013688       0.884619      0.105666\n",
       "9         0.911940       0.015478       0.884255      0.106524\n",
       "10        0.917048       0.016401       0.883928      0.106890\n",
       "11        0.921526       0.015827       0.883953      0.107177\n",
       "12        0.923403       0.015486       0.884099      0.107226\n",
       "13        0.926320       0.014841       0.885470      0.106431\n",
       "14        0.927658       0.013864       0.888541      0.101951\n",
       "15        0.928602       0.013328       0.890818      0.102645\n",
       "16        0.930901       0.012465       0.894751      0.100418\n",
       "17        0.932019       0.011421       0.894647      0.100435\n",
       "18        0.932679       0.010957       0.896842      0.100975\n",
       "19        0.933862       0.010060       0.902965      0.095437\n",
       "20        0.934024       0.010101       0.905206      0.095486\n",
       "21        0.934727       0.010160       0.905133      0.095690\n",
       "22        0.935721       0.009578       0.906155      0.095622\n",
       "23        0.936179       0.009800       0.907237      0.096224\n",
       "24        0.937854       0.008887       0.911485      0.090400\n",
       "25        0.937937       0.008909       0.911583      0.090592\n",
       "26        0.938273       0.009030       0.913578      0.088687\n",
       "27        0.938308       0.009028       0.913598      0.088667\n",
       "28        0.938364       0.009043       0.913605      0.088819\n",
       "29        0.938397       0.009046       0.913667      0.088876\n",
       "30        0.938445       0.009051       0.913856      0.089084\n",
       "31        0.938610       0.009089       0.913868      0.089064\n",
       "32        0.938730       0.009113       0.913821      0.089084\n",
       "33        0.938850       0.009014       0.913875      0.088996\n",
       "34        0.938945       0.008936       0.914201      0.089142\n",
       "35        0.939119       0.008783       0.914233      0.089012\n",
       "36        0.939233       0.008827       0.914381      0.088984\n",
       "37        0.939582       0.008942       0.914257      0.089050\n",
       "38        0.939693       0.008852       0.914335      0.089067\n",
       "39        0.939717       0.008860       0.914361      0.089032\n",
       "40        0.939920       0.008967       0.914369      0.089031\n",
       "41        0.940195       0.008699       0.916003      0.089530\n",
       "42        0.940306       0.008703       0.915981      0.089515\n",
       "43        0.940479       0.008730       0.915893      0.089429\n",
       "44        0.940492       0.008728       0.917242      0.088562\n",
       "45        0.940510       0.008738       0.917192      0.088515\n",
       "46        0.940525       0.008740       0.917245      0.088578\n",
       "47        0.940539       0.008744       0.917122      0.088480\n",
       "48        0.940551       0.008748       0.917238      0.088546\n",
       "49        0.941024       0.008394       0.917266      0.088635"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78432287",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Example of Training proccedure\n",
    "\n",
    "\n",
    "Let's now train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4eb12477",
   "metadata": {},
   "outputs": [],
   "source": [
    " bst=xgb.XGBClassifier(max_depth=10,learning_rate=0.01, n_estimators=50, objective='binary:logistic')\n",
    "# fit model\n",
    "model_used=bst.fit(x_total, y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a5d198a6-4596-4a9c-add6-974cff48fa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method XGBModel.evals_result of XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.01, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=10, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27f84e03",
   "metadata": {},
   "source": [
    "# Visualziating results (simple metrics)\n",
    "\n",
    "Let's see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3ae6e7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18480\\153130555.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_used\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredictions_binary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_test_binary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3_2022\\envs\\ML_tensor\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3_2022\\envs\\ML_tensor\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     \"\"\"\n\u001b[0;32m   1215\u001b[0m     \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'keepdims'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NoValue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3_2022\\envs\\ML_tensor\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = model_used.predict(x_test)\n",
    "predictions_binary = np.argmax(predictions, axis = 1)\n",
    "y_test_binary = np.argmax(y_test, axis=1)\n",
    "    \n",
    "cr = classification_report(y_test_binary, predictions_binary)\n",
    "cm = confusion_matrix(y_test_binary, predictions_binary)\n",
    "\n",
    "print(cm)\n",
    "print(\"Class 1 accuracy\")\n",
    "print(cm[0,0]/(cm[0,0]+cm[0,1]))\n",
    "\n",
    "print(\"Class 2 accuracy\")\n",
    "print(cm[1,1]/(cm[1,0]+cm[1,1]))\n",
    "\n",
    "#print(model_used.summary())\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f09fd1",
   "metadata": {},
   "source": [
    "# Visualziating results (Plots)\n",
    "\n",
    "Let's see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c37c5b56-65bb-4637-8dfd-801010b70c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.010448  , 0.02207899, 0.01320809, 0.01584152, 0.03114783,\n",
       "       0.43417573, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01752777, 0.02267887, 0.1015267 , 0.04768894, 0.02140178,\n",
       "       0.01614504, 0.01399788, 0.        , 0.        , 0.01146915,\n",
       "       0.01567686, 0.02016117, 0.03098541, 0.02174044, 0.0136462 ,\n",
       "       0.03390979, 0.01562648, 0.01158983, 0.01026439, 0.02290859,\n",
       "       0.02415452], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21df82b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7576\\1324738466.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mval_f1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_used\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_f1_m'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel_used\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel_used\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_f1 = model_used.history['val_f1_m']\n",
    "val_loss= model_used.history['val_loss']\n",
    "val_acc= model_used.history['val_acc']\n",
    "val_prec= model_used.history['val_precision_m']\n",
    "\n",
    "train_f1 = model_used.history['f1_m']\n",
    "train_loss = model_used.history['loss']\n",
    "train_acc = model_used.history['acc']\n",
    "train_prec = model_used.history['precision_m']\n",
    "\n",
    "plt.figure(figsize=(11.69,8.27))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(train_f1)\n",
    "plt.plot(val_f1)\n",
    "plt.ylabel('f1 score',fontsize=22)\n",
    "plt.legend(['train', 'test'], loc='lower right',fontsize=16)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.ylabel('loss',fontsize=22)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.xlabel('epochs',fontsize=22)\n",
    "plt.ylabel('acc',fontsize=22)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(train_prec)\n",
    "plt.plot(val_prec)\n",
    "plt.xlabel('epochs',fontsize=22)\n",
    "plt.ylabel('precision',fontsize=22)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
