{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf30b9ed-d763-4f9b-9a11-d067d34ebbec",
   "metadata": {},
   "source": [
    "## Original Publication\n",
    "\n",
    "See the original publication of this work in the following link: https://www.swsc-journal.org/articles/swsc/abs/2021/01/swsc210024/swsc210024.html\n",
    "\n",
    "Aminalragia-Giamini, Sigiava, et al. \"Solar Energetic Particle Event occurrence prediction using Solar Flare Soft X-ray measurements and Machine Learning.\" Journal of Space Weather and Space Climate 11 (2021): 59.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a378b43",
   "metadata": {},
   "source": [
    "# Loading Data \n",
    "\n",
    "## Importing libraries and data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20016c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import sys\n",
    "from os import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras \n",
    "import xgboost as xgb\n",
    "\n",
    "x_train = pd.read_pickle(\"x_train.pkl\")  \n",
    "x_test = pd.read_pickle(\"x_test.pkl\")  \n",
    "y_train = pd.read_pickle(\"y_train.pkl\")  \n",
    "y_test = pd.read_pickle(\"y_test.pkl\")  \n",
    "\n",
    "# number of different classes\n",
    "n_SEPS =  226\n",
    "n_flares = 17875\n",
    "n_sample = n_SEPS +n_flares\n",
    "columns_to_use = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','17','20','21','22','28','39','40',\n",
    "                       '41','42','43','44','45','46','47','48']\n",
    "number_of_classes = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae342553-12a1-45ca-b0a0-36e920a330e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Savva\\AppData\\Local\\Temp\\ipykernel_18480\\4287163944.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  x_total = x_train.append(x_test)\n",
      "C:\\Users\\Savva\\AppData\\Local\\Temp\\ipykernel_18480\\4287163944.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_total = y_train.append(y_test)\n"
     ]
    }
   ],
   "source": [
    "x_total = x_train.append(x_test)\n",
    "y_total = y_train.append(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e4783",
   "metadata": {},
   "source": [
    "## Prepare validation\n",
    "\n",
    "Establish validation method below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b48ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from xgboost import cv\n",
    "\n",
    "sample_weight = compute_sample_weight(class_weight='balanced',y=y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10706183-fa4d-46f1-8a6a-33bc4f67865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = xgb.DMatrix(x_total, label=y_total)\n",
    "\n",
    "params={\"objective\" : \"binary:logistic\", 'learning_rate' :0.01, 'max_depth':20}\n",
    "\n",
    "xgb_cv = cv(dtrain=d_train, params =params, nfold=50, metrics =\"auc\", num_boost_round=50,as_pandas =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "14ad755c-6d22-48e0-8483-b518395f4294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.887939</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>0.856415</td>\n",
       "      <td>0.039463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.891254</td>\n",
       "      <td>0.011045</td>\n",
       "      <td>0.858277</td>\n",
       "      <td>0.038011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.898137</td>\n",
       "      <td>0.008620</td>\n",
       "      <td>0.870872</td>\n",
       "      <td>0.025931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.903944</td>\n",
       "      <td>0.012010</td>\n",
       "      <td>0.878711</td>\n",
       "      <td>0.016897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905119</td>\n",
       "      <td>0.012243</td>\n",
       "      <td>0.878632</td>\n",
       "      <td>0.016696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.905146</td>\n",
       "      <td>0.012261</td>\n",
       "      <td>0.878696</td>\n",
       "      <td>0.016728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.909858</td>\n",
       "      <td>0.011246</td>\n",
       "      <td>0.878555</td>\n",
       "      <td>0.016909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.909845</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.878552</td>\n",
       "      <td>0.016914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.909900</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>0.878525</td>\n",
       "      <td>0.016892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.910523</td>\n",
       "      <td>0.011665</td>\n",
       "      <td>0.882641</td>\n",
       "      <td>0.020118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.910541</td>\n",
       "      <td>0.011664</td>\n",
       "      <td>0.882608</td>\n",
       "      <td>0.020141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.910600</td>\n",
       "      <td>0.011698</td>\n",
       "      <td>0.882679</td>\n",
       "      <td>0.020130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.911161</td>\n",
       "      <td>0.012177</td>\n",
       "      <td>0.882570</td>\n",
       "      <td>0.020075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.919492</td>\n",
       "      <td>0.012606</td>\n",
       "      <td>0.896009</td>\n",
       "      <td>0.034161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.920597</td>\n",
       "      <td>0.011044</td>\n",
       "      <td>0.895958</td>\n",
       "      <td>0.034175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.920617</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.896004</td>\n",
       "      <td>0.034158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.920668</td>\n",
       "      <td>0.011010</td>\n",
       "      <td>0.896161</td>\n",
       "      <td>0.034429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.920713</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.896069</td>\n",
       "      <td>0.034442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.920751</td>\n",
       "      <td>0.011018</td>\n",
       "      <td>0.896092</td>\n",
       "      <td>0.034440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.925601</td>\n",
       "      <td>0.011019</td>\n",
       "      <td>0.899126</td>\n",
       "      <td>0.035663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.925658</td>\n",
       "      <td>0.011045</td>\n",
       "      <td>0.899136</td>\n",
       "      <td>0.035554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.925679</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>0.899110</td>\n",
       "      <td>0.035601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.925706</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.899132</td>\n",
       "      <td>0.035611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.926356</td>\n",
       "      <td>0.011255</td>\n",
       "      <td>0.899034</td>\n",
       "      <td>0.035733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.927410</td>\n",
       "      <td>0.009593</td>\n",
       "      <td>0.905070</td>\n",
       "      <td>0.032734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.927443</td>\n",
       "      <td>0.009560</td>\n",
       "      <td>0.905100</td>\n",
       "      <td>0.032714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.927455</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.905120</td>\n",
       "      <td>0.032620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.927477</td>\n",
       "      <td>0.009501</td>\n",
       "      <td>0.905161</td>\n",
       "      <td>0.032652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.927530</td>\n",
       "      <td>0.009525</td>\n",
       "      <td>0.905212</td>\n",
       "      <td>0.032665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.927537</td>\n",
       "      <td>0.009513</td>\n",
       "      <td>0.905226</td>\n",
       "      <td>0.032633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.927549</td>\n",
       "      <td>0.009497</td>\n",
       "      <td>0.905245</td>\n",
       "      <td>0.032643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.927555</td>\n",
       "      <td>0.009485</td>\n",
       "      <td>0.905239</td>\n",
       "      <td>0.032608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.927587</td>\n",
       "      <td>0.009504</td>\n",
       "      <td>0.905262</td>\n",
       "      <td>0.032605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.928683</td>\n",
       "      <td>0.010797</td>\n",
       "      <td>0.905284</td>\n",
       "      <td>0.032623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.929280</td>\n",
       "      <td>0.010960</td>\n",
       "      <td>0.905274</td>\n",
       "      <td>0.032639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.929285</td>\n",
       "      <td>0.010954</td>\n",
       "      <td>0.905262</td>\n",
       "      <td>0.032603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.929309</td>\n",
       "      <td>0.010970</td>\n",
       "      <td>0.905337</td>\n",
       "      <td>0.032555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.929797</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>0.907516</td>\n",
       "      <td>0.029215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.929817</td>\n",
       "      <td>0.011172</td>\n",
       "      <td>0.907525</td>\n",
       "      <td>0.029206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.929816</td>\n",
       "      <td>0.011174</td>\n",
       "      <td>0.909325</td>\n",
       "      <td>0.030075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.937803</td>\n",
       "      <td>0.009184</td>\n",
       "      <td>0.914695</td>\n",
       "      <td>0.029974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.937885</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.914741</td>\n",
       "      <td>0.029915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.937889</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>0.914738</td>\n",
       "      <td>0.029927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.937945</td>\n",
       "      <td>0.009340</td>\n",
       "      <td>0.914757</td>\n",
       "      <td>0.029916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.938517</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>0.914773</td>\n",
       "      <td>0.029932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.939535</td>\n",
       "      <td>0.009493</td>\n",
       "      <td>0.916883</td>\n",
       "      <td>0.026528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.942678</td>\n",
       "      <td>0.012347</td>\n",
       "      <td>0.922933</td>\n",
       "      <td>0.018215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.942724</td>\n",
       "      <td>0.012385</td>\n",
       "      <td>0.922990</td>\n",
       "      <td>0.018266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.942750</td>\n",
       "      <td>0.012406</td>\n",
       "      <td>0.923071</td>\n",
       "      <td>0.018296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.942807</td>\n",
       "      <td>0.012479</td>\n",
       "      <td>0.923134</td>\n",
       "      <td>0.018235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
       "0         0.887939       0.012634       0.856415      0.039463\n",
       "1         0.891254       0.011045       0.858277      0.038011\n",
       "2         0.898137       0.008620       0.870872      0.025931\n",
       "3         0.903944       0.012010       0.878711      0.016897\n",
       "4         0.905119       0.012243       0.878632      0.016696\n",
       "5         0.905146       0.012261       0.878696      0.016728\n",
       "6         0.909858       0.011246       0.878555      0.016909\n",
       "7         0.909845       0.011244       0.878552      0.016914\n",
       "8         0.909900       0.011270       0.878525      0.016892\n",
       "9         0.910523       0.011665       0.882641      0.020118\n",
       "10        0.910541       0.011664       0.882608      0.020141\n",
       "11        0.910600       0.011698       0.882679      0.020130\n",
       "12        0.911161       0.012177       0.882570      0.020075\n",
       "13        0.919492       0.012606       0.896009      0.034161\n",
       "14        0.920597       0.011044       0.895958      0.034175\n",
       "15        0.920617       0.011009       0.896004      0.034158\n",
       "16        0.920668       0.011010       0.896161      0.034429\n",
       "17        0.920713       0.011009       0.896069      0.034442\n",
       "18        0.920751       0.011018       0.896092      0.034440\n",
       "19        0.925601       0.011019       0.899126      0.035663\n",
       "20        0.925658       0.011045       0.899136      0.035554\n",
       "21        0.925679       0.011041       0.899110      0.035601\n",
       "22        0.925706       0.011036       0.899132      0.035611\n",
       "23        0.926356       0.011255       0.899034      0.035733\n",
       "24        0.927410       0.009593       0.905070      0.032734\n",
       "25        0.927443       0.009560       0.905100      0.032714\n",
       "26        0.927455       0.009527       0.905120      0.032620\n",
       "27        0.927477       0.009501       0.905161      0.032652\n",
       "28        0.927530       0.009525       0.905212      0.032665\n",
       "29        0.927537       0.009513       0.905226      0.032633\n",
       "30        0.927549       0.009497       0.905245      0.032643\n",
       "31        0.927555       0.009485       0.905239      0.032608\n",
       "32        0.927587       0.009504       0.905262      0.032605\n",
       "33        0.928683       0.010797       0.905284      0.032623\n",
       "34        0.929280       0.010960       0.905274      0.032639\n",
       "35        0.929285       0.010954       0.905262      0.032603\n",
       "36        0.929309       0.010970       0.905337      0.032555\n",
       "37        0.929797       0.011161       0.907516      0.029215\n",
       "38        0.929817       0.011172       0.907525      0.029206\n",
       "39        0.929816       0.011174       0.909325      0.030075\n",
       "40        0.937803       0.009184       0.914695      0.029974\n",
       "41        0.937885       0.009290       0.914741      0.029915\n",
       "42        0.937889       0.009289       0.914738      0.029927\n",
       "43        0.937945       0.009340       0.914757      0.029916\n",
       "44        0.938517       0.009313       0.914773      0.029932\n",
       "45        0.939535       0.009493       0.916883      0.026528\n",
       "46        0.942678       0.012347       0.922933      0.018215\n",
       "47        0.942724       0.012385       0.922990      0.018266\n",
       "48        0.942750       0.012406       0.923071      0.018296\n",
       "49        0.942807       0.012479       0.923134      0.018235"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78432287",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Example of Training proccedure\n",
    "\n",
    "\n",
    "Let's now train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4eb12477",
   "metadata": {},
   "outputs": [],
   "source": [
    " bst=xgb.XGBClassifier(max_depth=10,learning_rate=0.01, n_estimators=50, objective='binary:logistic')\n",
    "# fit model\n",
    "model_used=bst.fit(x_total, y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a5d198a6-4596-4a9c-add6-974cff48fa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method XGBModel.evals_result of XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.01, max_bin=256,\n",
       "              max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,\n",
       "              max_depth=10, max_leaves=0, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=50, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0, ...)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27f84e03",
   "metadata": {},
   "source": [
    "# Visualziating results (simple metrics)\n",
    "\n",
    "Let's see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3ae6e7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18480\\153130555.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_used\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredictions_binary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0my_test_binary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3_2022\\envs\\ML_tensor\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3_2022\\envs\\ML_tensor\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     \"\"\"\n\u001b[0;32m   1215\u001b[0m     \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'keepdims'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NoValue\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3_2022\\envs\\ML_tensor\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = model_used.predict(x_test)\n",
    "predictions_binary = np.argmax(predictions, axis = 1)\n",
    "y_test_binary = np.argmax(y_test, axis=1)\n",
    "    \n",
    "cr = classification_report(y_test_binary, predictions_binary)\n",
    "cm = confusion_matrix(y_test_binary, predictions_binary)\n",
    "\n",
    "print(cm)\n",
    "print(\"Class 1 accuracy\")\n",
    "print(cm[0,0]/(cm[0,0]+cm[0,1]))\n",
    "\n",
    "print(\"Class 2 accuracy\")\n",
    "print(cm[1,1]/(cm[1,0]+cm[1,1]))\n",
    "\n",
    "#print(model_used.summary())\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f09fd1",
   "metadata": {},
   "source": [
    "# Visualziating results (Plots)\n",
    "\n",
    "Let's see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c37c5b56-65bb-4637-8dfd-801010b70c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.010448  , 0.02207899, 0.01320809, 0.01584152, 0.03114783,\n",
       "       0.43417573, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01752777, 0.02267887, 0.1015267 , 0.04768894, 0.02140178,\n",
       "       0.01614504, 0.01399788, 0.        , 0.        , 0.01146915,\n",
       "       0.01567686, 0.02016117, 0.03098541, 0.02174044, 0.0136462 ,\n",
       "       0.03390979, 0.01562648, 0.01158983, 0.01026439, 0.02290859,\n",
       "       0.02415452], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21df82b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBClassifier' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7576\\1324738466.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mval_f1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_used\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_f1_m'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel_used\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel_used\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XGBClassifier' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_f1 = model_used.history['val_f1_m']\n",
    "val_loss= model_used.history['val_loss']\n",
    "val_acc= model_used.history['val_acc']\n",
    "val_prec= model_used.history['val_precision_m']\n",
    "\n",
    "train_f1 = model_used.history['f1_m']\n",
    "train_loss = model_used.history['loss']\n",
    "train_acc = model_used.history['acc']\n",
    "train_prec = model_used.history['precision_m']\n",
    "\n",
    "plt.figure(figsize=(11.69,8.27))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(train_f1)\n",
    "plt.plot(val_f1)\n",
    "plt.ylabel('f1 score',fontsize=22)\n",
    "plt.legend(['train', 'test'], loc='lower right',fontsize=16)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.ylabel('loss',fontsize=22)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(train_acc)\n",
    "plt.plot(val_acc)\n",
    "plt.xlabel('epochs',fontsize=22)\n",
    "plt.ylabel('acc',fontsize=22)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(train_prec)\n",
    "plt.plot(val_prec)\n",
    "plt.xlabel('epochs',fontsize=22)\n",
    "plt.ylabel('precision',fontsize=22)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
