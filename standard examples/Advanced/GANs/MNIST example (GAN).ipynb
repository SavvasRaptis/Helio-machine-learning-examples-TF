{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "\n",
    "## Importing libraries\n",
    "\n",
    "As a first step we load the different libraries we are going to use, in this simple example we only need tensorflow (keras) and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-27 00:02:30.880757: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import BatchNormalization,Dropout,Flatten, MaxPooling2D, Conv2D\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU,ELU,ThresholdedReLU,ReLU\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "Next step is to actually load the MNIST database and perform some simple pre-process in order to introduce it to the neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-27 00:05:44.089687: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-27 00:05:44.089837: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data() # we load the data from keras.datsets library, here we only need the training set\n",
    "\n",
    "## Normalization ##\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255 # images are encoded with up to 256 so to normalize from 0-1 we simply divide\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# Assisting variables to plot examples\n",
    "y_train_initial = y_train\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "buffer_size = 40000\n",
    "batch_size = 128\n",
    "\n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(buffer_size).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show that the generator is not working (not trained yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa621526350>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the descriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the descriminator and the generator loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add optimizers for each of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([batch_size, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # Produce images for the GIF as you go\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # Save the model every 15 epochs\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # Notice `training` is set to False.\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-27 00:15:28.570486: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [60000,28,28,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-01-27 00:15:28.571185: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [60000,28,28,1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "in user code:\n\n    File \"/var/folders/vs/s8nbsg4x7nd44x9k_00v8f0m0000gq/T/ipykernel_43537/3248131820.py\", line 5, in train_step  *\n        noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    NameError: name 'BATCH_SIZE' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m----> 6\u001b[0m   \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Produce images for the GIF as you go\u001b[39;00m\n\u001b[1;32m      9\u001b[0m display\u001b[38;5;241m.\u001b[39mclear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml-env/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/vs/s8nbsg4x7nd44x9k_00v8f0m0000gq/T/__autograph_generated_fileektnwmuq.py:8\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_step\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtf__train_step\u001b[39m(images):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mFunctionScope(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_step\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfscope\u001b[39m\u001b[38;5;124m'\u001b[39m, ag__\u001b[38;5;241m.\u001b[39mConversionOptions(recursive\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, user_requested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, optional_features\u001b[38;5;241m=\u001b[39m(), internal_convert_user_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)) \u001b[38;5;28;01mas\u001b[39;00m fscope:\n\u001b[0;32m----> 8\u001b[0m         noise \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal, ([ag__\u001b[38;5;241m.\u001b[39mld(\u001b[43mBATCH_SIZE\u001b[49m), ag__\u001b[38;5;241m.\u001b[39mld(noise_dim)],), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m gen_tape, ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m disc_tape:\n\u001b[1;32m     10\u001b[0m             generated_images \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(generator), (ag__\u001b[38;5;241m.\u001b[39mld(noise),), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)\n",
      "\u001b[0;31mNameError\u001b[0m: in user code:\n\n    File \"/var/folders/vs/s8nbsg4x7nd44x9k_00v8f0m0000gq/T/ipykernel_43537/3248131820.py\", line 5, in train_step  *\n        noise = tf.random.normal([BATCH_SIZE, noise_dim])\n\n    NameError: name 'BATCH_SIZE' is not defined\n"
     ]
    }
   ],
   "source": [
    "train(train_dataset, n_epochs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
